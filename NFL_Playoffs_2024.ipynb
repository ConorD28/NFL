{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ConorD28/NFL/blob/main/NFL_Playoffs_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq6xsPJUvkXO",
        "outputId": "ba98e8a1-972c-48a1-ef77-855998b8ed2d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "%matplotlib inline\n",
        "inputs = pd.read_csv('NFL oPPG inputs.csv')\n",
        "playoff_stats = pd.read_csv('playoff_stats_NFL.csv')\n",
        "\n",
        "print(inputs.isnull().sum().sum()) #Check if there are NA values\n",
        "print(playoff_stats.isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9zr28DwjQ6D"
      },
      "source": [
        "\n",
        "\n",
        "# **Correlation/Scores**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import final\n",
        "import re\n",
        "def remove_similar_cols(df):\n",
        "  top_num = 8\n",
        "  df['group'] = df.index.str.split('_').str[0]\n",
        "  df = df.groupby('group', group_keys=False).apply(lambda x: x.loc[x['corrs'].abs().nlargest(top_num).index])\n",
        "  df = df.drop('group', axis = 1)\n",
        "\n",
        "  # Extract all unique phrases from the indices\n",
        "  def extract_phrases(index):\n",
        "      phrases = set()\n",
        "      for idx in index:\n",
        "          phrases.update(re.split(r'\\*|&', idx))\n",
        "      return phrases\n",
        "\n",
        "  phrases = extract_phrases(df.index)\n",
        "\n",
        "  # Initialize counters to track how many times each phrase has appeared before *, after *, or by itself\n",
        "  phrase_counts = {phrase: {'before': 0, 'after': 0, 'isolated': 0} for phrase in phrases}\n",
        "\n",
        "  # Create an empty DataFrame to store results\n",
        "  final_rows = pd.DataFrame()\n",
        "\n",
        "  # Track rows that have already been added\n",
        "  seen_rows = set()\n",
        "\n",
        "  # Process rows sorted by correlation (highest to lowest)\n",
        "  for row in df.sort_values(by='corrs', ascending=False).itertuples():\n",
        "      row_index = row.Index\n",
        "      row_phrases = re.split(r'\\*|&', row_index)\n",
        "\n",
        "      # Determine positions for the phrases in the row\n",
        "      positions = {'before': set(), 'after': set(), 'isolated': set()}\n",
        "\n",
        "      if len(row_phrases) == 1:\n",
        "          # Only one phrase (isolated)\n",
        "          positions['isolated'].add(row_phrases[0])\n",
        "      else:\n",
        "          # Multiple phrases (before and after the *)\n",
        "          positions['before'].add(row_phrases[0])\n",
        "          positions['after'].add(row_phrases[-1])\n",
        "          positions['isolated'].update(row_phrases)\n",
        "\n",
        "      # Check if adding this row violates the limit for any phrase in any position\n",
        "      if any(phrase_counts[phrase]['before'] >= top_num or phrase_counts[phrase]['after'] >= top_num or phrase_counts[phrase]['isolated'] >= top_num for phrase in positions['before'].union(positions['after'], positions['isolated'])):\n",
        "          continue  # Skip this row if any phrase exceeds the limit in any position\n",
        "\n",
        "      # Add the row if it doesn't exceed the limit for any phrase\n",
        "      final_rows = pd.concat([final_rows, df.loc[[row_index]]])\n",
        "      seen_rows.add(row_index)\n",
        "\n",
        "      # Update the phrase counts for the phrases in this row and position\n",
        "      for position in positions:\n",
        "          for phrase in positions[position]:\n",
        "              if phrase_counts[phrase][position] < top_num:\n",
        "                  phrase_counts[phrase][position] += 1\n",
        "\n",
        "  # Sort final results and reset the index for readability\n",
        "  final_rows = final_rows.sort_values(by='corrs', ascending=False)\n",
        "  return final_rows"
      ],
      "metadata": {
        "id": "mK-R3iPEMUuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2LtJLaEVvqfY"
      },
      "outputs": [],
      "source": [
        "import scipy.stats\n",
        "def correlation(dataset, threshold, target): #Function to get Pearson's correlation between input and target\n",
        "  data = []\n",
        "  cols = []\n",
        "  correlations = []\n",
        "  if isinstance(target, np.ndarray):\n",
        "    target = pd.Series(target)\n",
        "  for col in dataset.columns:\n",
        "      cor2 = dataset.loc[:,col].corr(target) #scipy.stats.spearmanr(dataset.loc[:,col], target)[0] and scipy.stats.kendalltau(dataset.loc[:,col], target)[0]\n",
        "      if abs(cor2) > threshold:\n",
        "        data.append(dataset.loc[:,col]) #make list of columns that meet the threshold\n",
        "        cols.append(col)\n",
        "        correlations.append(cor2) #make list of correlations that meet the threshold\n",
        "\n",
        "  if len(data) == 0:\n",
        "     return pd.DataFrame()\n",
        "\n",
        "  df = pd.DataFrame(data)\n",
        "  df_len = len(df.columns)\n",
        "  df.insert(df_len, 'corrs', correlations)\n",
        "  df = df.sort_values(by=df.columns[-1], ascending=False, key = abs)\n",
        "  df = remove_similar_cols(df)\n",
        "  df = df.sort_values(by=df.columns[-1], ascending=False, key = abs)\n",
        "  df = df.transpose()\n",
        "  df_corrs = df.iloc[-1:, :]\n",
        "  df = df.drop(df.tail(1).index)\n",
        "  return df, df_corrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngjdaqWIvssV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from numpy.random.mtrand import random_sample\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV, MultiTaskLassoCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5q3JY8L1e1M"
      },
      "outputs": [],
      "source": [
        "def Scores(y, y_pred):\n",
        "  MSE = mean_squared_error(y, y_pred)\n",
        "  MAE = mean_absolute_error(y, y_pred)\n",
        "\n",
        "  range_y = y.max() - y.min()\n",
        "  MAPE = -1\n",
        "  Avg_Normalized_Score = -1\n",
        "  print(\"Normalized by range:\")\n",
        "  if range_y == 0:\n",
        "    print(\"Range was 0 so not Normalized by range:\")\n",
        "    Normalized_RMSE = -1\n",
        "    Normalized_MAE = -1\n",
        "    MAPE = abs((y_pred - y))/y\n",
        "  else:\n",
        "    Normalized_RMSE = (np.sqrt(MSE)/abs(range_y))\n",
        "    Normalized_MAE = (MAE/abs(range_y))\n",
        "    Avg_Normalized_Score = (Normalized_RMSE + Normalized_MAE)/2\n",
        "    Avg_Normalized_Score = Avg_Normalized_Score.item() if isinstance(Avg_Normalized_Score, np.ndarray) else Avg_Normalized_Score\n",
        "    print(f'Avg. Normalized Score:{ Avg_Normalized_Score:.1f}')\n",
        "    print(f'Normalized RMSE:{ Normalized_RMSE:.1f}')\n",
        "    print(f'Normalized MAE:{ Normalized_MAE:.2f}')\n",
        "\n",
        "  #Calculate average error, handling single-element arrays and ensuring it is a scalar\n",
        "  avg_error = np.mean(np.abs(y_pred-y))\n",
        "\n",
        "  #print(f'MAE:{ MAE:.3f}')\n",
        "  #print(f'RMSE:{ np.sqrt(MSE):.3f}')\n",
        "  #print(f'Avg. Error:{avg_error:.4f}')\n",
        "  return Avg_Normalized_Score, avg_error, MAPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifryB2OHrVml"
      },
      "outputs": [],
      "source": [
        "def Predict_Scores(model, X_tr, X_te, y_tr, y_te, t_sc):#, predict_df):\n",
        "  y_train_pred = model.predict(X_tr)\n",
        "  #print(y_train_pred)\n",
        "\n",
        "  if len(y_te) != 0:\n",
        "    y_test_pred = model.predict(X_te)\n",
        "  else:\n",
        "    y_test_pred = pd.DataFrame()\n",
        "    Avg_N_Score_test = 0\n",
        "\n",
        "  #Training Scores:\n",
        "  Avg_N_Score_train, avg_error_train, MAPE = Scores(y_tr, y_train_pred)\n",
        "  Avg_N_Score_train = Avg_N_Score_train.item() if isinstance(Avg_N_Score_train, np.ndarray) else Avg_N_Score_train\n",
        "  avg_error_train = avg_error_train.reshape(-1, 1) #\n",
        "  avg_error_test = 0\n",
        "  avg_error_test_transformed = 0\n",
        "  MAPE_test = 0\n",
        "\n",
        "  #Test Predictions:\n",
        "  if len(y_te) != 0:\n",
        "    print(\"Test predictions:\")\n",
        "    #Testing Scores:\n",
        "    Avg_N_Score_test, avg_error_test, MAPE_test = Scores(y_te, y_test_pred)\n",
        "    MAPE_test = MAPE_test.item() if isinstance(MAPE_test, np.ndarray) else MAPE_test\n",
        "    print(f'MAPE:{ MAPE_test:.2f}')\n",
        "    print()\n",
        "    print('after inverse transform, testing off by:')\n",
        "    y_test_pred_transformed = t_sc.inverse_transform(y_test_pred.reshape(-1, 1))\n",
        "    y_test_pred_transformed = pd.Series(y_test_pred_transformed.flatten())\n",
        "    y_te_transformed = t_sc.inverse_transform(y_te.reshape(-1, 1))\n",
        "    y_te_transformed = pd.Series(y_te_transformed.flatten())\n",
        "    avg_error_test_transformed = np.abs(y_te_transformed - y_test_pred_transformed)\n",
        "    #print(avg_error_test_transformed)\n",
        "\n",
        "  print('after inverse transform, training off by:')\n",
        "  y_train_pred_transformed = t_sc.inverse_transform(y_train_pred.reshape(-1, 1)) # Reshape y_train_pred\n",
        "  y_train_pred_transformed = pd.Series(y_train_pred_transformed.flatten())\n",
        "  y_tr_transformed = t_sc.inverse_transform(y_tr.values.reshape(-1, 1))\n",
        "  y_tr_transformed = pd.Series(y_tr_transformed.flatten())\n",
        "  avg_error_train_transformed = np.mean(np.abs(y_tr_transformed - y_train_pred_transformed))\n",
        "  #print(avg_error_train_transformed)\n",
        "  #print(y_tr_transformed - y_train_pred_transformed)\n",
        "  print(y_train_pred_transformed)\n",
        "\n",
        "  #Predict:\n",
        "  #predictions = model.predict(predict_df)\n",
        "\n",
        "  return Avg_N_Score_train, Avg_N_Score_test, avg_error_train_transformed, avg_error_test_transformed, MAPE_test#, predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhvX9hZQi5U7"
      },
      "source": [
        "# **ML Tuning Algorithms**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Cvp4C7sqoRZx"
      },
      "outputs": [],
      "source": [
        "!pip install optuna\n",
        "import optuna\n",
        "!pip install joblib\n",
        "import joblib\n",
        "from sklearn.model_selection import cross_val_score\n",
        "def Ridge_tune(X_train, y_train, cv_choice, num_trials, timeout_choice):\n",
        "    def objective(trial, cv_runs, X_train, y_train):\n",
        "      alpha = trial.suggest_float(\"alpha\", 2, 10, log=True)#1e-4, 10.0; Alpha is the regularization strength\n",
        "      solver = trial.suggest_categorical(\"solver\", [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"])\n",
        "\n",
        "      model = Ridge(alpha=alpha, solver=solver, random_state=28)\n",
        "      score = cross_val_score(model, X_train, y_train, cv=cv_runs, scoring=\"neg_mean_squared_error\").mean()\n",
        "      return -score  # Minimize the MSE\n",
        "\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(lambda trial: objective(trial, cv_choice, X_train, y_train), n_trials=num_trials, timeout=timeout_choice)\n",
        "\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "    print(f\"  Params: {trial.params}\")\n",
        "\n",
        "    best_model = Ridge(**trial.params, random_state=28)\n",
        "    best_model.fit(X_train, y_train)\n",
        "    #joblib.dump(best_model, 'PPG_Ridge.pkl')\n",
        "    return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3O8UenllL9Tt"
      },
      "outputs": [],
      "source": [
        "def Lasso_tune(X_train, y_train, cv_choice, num_trials, timeout_choice):\n",
        "  def Lasso_objective(trial, cv_runs, X_train, y_train):\n",
        "    alpha = trial.suggest_float(\"alpha\", 2, 10, log=True)##1e-4, 10.0; Regularization strength\n",
        "    max_iter = trial.suggest_int(\"max_iter\", 1000, 10000, step=100)  # Max iterations\n",
        "    tol = trial.suggest_float(\"tol\", 1e-5, 1e-2, log=True)  # Tolerance for stopping criteria\n",
        "\n",
        "    model = Lasso(alpha=alpha, max_iter=max_iter, tol=tol, random_state=28)\n",
        "    score = cross_val_score(model, X_train, y_train, cv=cv_runs, scoring=\"neg_mean_squared_error\").mean()\n",
        "    return -score  # Minimize the MSE\n",
        "\n",
        "  study = optuna.create_study(direction=\"minimize\")\n",
        "  study.optimize(lambda trial: Lasso_objective(trial, cv_choice, X_train, y_train), n_trials=num_trials, timeout=timeout_choice)\n",
        "  print(\"Best trial:\")\n",
        "  trial = study.best_trial\n",
        "  print(f\"  Params: {trial.params}\")\n",
        "\n",
        "  best_model = Lasso(**trial.params, random_state=28)\n",
        "  best_model.fit(X_train, y_train)\n",
        "  #joblib.dump(best_model, 'PPG_Lasso.pkl')\n",
        "  return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arifqUP7P65I"
      },
      "outputs": [],
      "source": [
        "def Elastic_tune(X_train, y_train, cv_choice, num_trials, timeout_choice):\n",
        "  def Elastic_objective(trial, cv_runs, X_train, y_train):\n",
        "    alpha = trial.suggest_float(\"alpha\", 2, 10, log=True)#1e-4, 10.0; Regularization strength\n",
        "    l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0)  # Mixing ratio between Lasso and Ridge\n",
        "    max_iter = trial.suggest_int(\"max_iter\", 1000, 10000, step=100)  # Max iterations\n",
        "    tol = trial.suggest_float(\"tol\", 1e-5, 1e-2, log=True)  # Tolerance for stopping criteria\n",
        "\n",
        "    model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, max_iter=max_iter, tol=tol, random_state=28)\n",
        "    score = cross_val_score(model, X_train, y_train, cv=cv_runs, scoring=\"neg_mean_squared_error\").mean()\n",
        "    return -score  # Minimize the MSE\n",
        "\n",
        "  study = optuna.create_study(direction=\"minimize\")\n",
        "  study.optimize(lambda trial: Elastic_objective(trial, cv_choice, X_train, y_train), n_trials=num_trials, timeout=timeout_choice)\n",
        "\n",
        "  print(\"Best trial:\")\n",
        "  trial = study.best_trial\n",
        "  print(f\"  Params: {trial.params}\")\n",
        "\n",
        "  best_model = ElasticNet(**trial.params, random_state=28)\n",
        "  best_model.fit(X_train, y_train)\n",
        "  #joblib.dump(best_model, 'PPG_Elastic.pkl')\n",
        "  return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFcBEcqFsezZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "def GBR_tune(X_train, y_train, cv_choice, num_trials, timeout_choice):\n",
        "  def GBR_objective(trial, cv_runs, X_train, y_train):\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True), #1e-3, 0.5\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
        "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
        "        \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None]),\n",
        "    }\n",
        "    model = GradientBoostingRegressor(**params, random_state=28)\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=cv_runs, scoring=\"neg_mean_squared_error\")\n",
        "    return -scores.mean()  # Minimize MSE\n",
        "\n",
        "  study = optuna.create_study(direction=\"minimize\")\n",
        "  study.optimize(lambda trial: GBR_objective(trial, cv_choice, X_train, y_train), n_trials=num_trials, timeout=timeout_choice)\n",
        "  print(\"Best parameters:\", study.best_params)\n",
        "\n",
        "  best_model = GradientBoostingRegressor(**study.best_params, random_state=28)\n",
        "  best_model.fit(X_train, y_train)\n",
        "  joblib.dump(best_model, 'PPG_GBR.pkl')\n",
        "  return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S79aLVgXqwdw"
      },
      "outputs": [],
      "source": [
        "def SVR_rbf_tune(X_train, y_train, cv_choice, num_trials, timeout_choice):\n",
        "  def rbf_objective(trial, cv_runs, X_train, y_train):\n",
        "      C = trial.suggest_float('C', 1e-3, 1e3, log=True)\n",
        "      gamma = trial.suggest_float('gamma', 1e-4, 1e1, log=True)\n",
        "      epsilon = trial.suggest_float('epsilon', 1e-4, 1e1, log=True)\n",
        "\n",
        "      model = SVR(kernel='rbf', C=C, gamma=gamma, epsilon=epsilon)\n",
        "      scores = cross_val_score(model, X_train, y_train, cv=cv_runs, scoring='neg_mean_squared_error')\n",
        "      mean_score = np.mean(scores)\n",
        "      return -mean_score\n",
        "\n",
        "  study = optuna.create_study(direction='minimize')\n",
        "  study.optimize(lambda trial: rbf_objective(trial, cv_choice, X_train, y_train), n_trials=num_trials, timeout=timeout_choice)\n",
        "  print(\"Best parameters:\", study.best_params)\n",
        "  best_model = SVR(kernel='rbf', C=study.best_params['C'], gamma=study.best_params['gamma'],\n",
        "                 epsilon=study.best_params['epsilon'])\n",
        "  best_model.fit(X_train, y_train)\n",
        "  #joblib.dump(best_model, 'PPG_Rbf.pkl')\n",
        "  return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhMpaUciufvj"
      },
      "outputs": [],
      "source": [
        "def SVR_poly_tune(X_train, y_train, cv_choice, num_trials, timeout_choice):\n",
        "  def poly_objective(trial, cv_runs, X_train, y_train):\n",
        "    C = trial.suggest_float('C', 1e-3, 1e3, log=True)\n",
        "    gamma = trial.suggest_float('gamma', 1e-4, 1e1, log=True)\n",
        "    epsilon = trial.suggest_float('epsilon', 1e-4, 1e1, log=True)\n",
        "    degree = trial.suggest_int('degree', 2, 5)  # Degrees 2 through 5\n",
        "    coef0 = trial.suggest_float('coef0', 0.0, 10.0)  # Coefficient in kernel function\n",
        "\n",
        "    model = SVR(kernel='poly', C=C, gamma=gamma, epsilon=epsilon, degree=degree, coef0=coef0)\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=cv_runs, scoring='neg_mean_squared_error')\n",
        "    mean_score = np.mean(scores)\n",
        "    return -mean_score\n",
        "\n",
        "  study = optuna.create_study(direction='minimize')\n",
        "  study.optimize(lambda trial: poly_objective(trial, cv_choice, X_train, y_train), n_trials=num_trials, timeout=timeout_choice)\n",
        "  print(\"Best parameters:\", study.best_params)\n",
        "\n",
        "  best_model = SVR(kernel='poly', C=study.best_params['C'], gamma=study.best_params['gamma'],\n",
        "                  epsilon=study.best_params['epsilon'], degree=study.best_params['degree'],\n",
        "                  coef0=study.best_params['coef0'])\n",
        "  best_model.fit(X_train, y_train)\n",
        "  #joblib.dump(best_model, 'PPG_Poly.pkl')\n",
        "  return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49dqq-GiW8IS"
      },
      "outputs": [],
      "source": [
        "def SVR_tune(X_train, y_train, cv_choice, num_trials, timeout_choice):\n",
        "  def linear_svr_objective(trial, cv_runs, X_train, y_train):\n",
        "    C = trial.suggest_float('C', 1e-4, .8, log=True) #1e-4, 1e2\n",
        "    epsilon = trial.suggest_float('epsilon', 1e-4, 1.0, log=True)\n",
        "    model = LinearSVR(C=C, epsilon=epsilon, random_state=28, max_iter=100000)\n",
        "\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=cv_runs, scoring='neg_mean_squared_error')\n",
        "    mean_score = np.mean(scores)\n",
        "    return -mean_score\n",
        "\n",
        "  study = optuna.create_study(direction='minimize')\n",
        "  study.optimize(lambda trial: linear_svr_objective(trial, cv_choice, X_train, y_train), n_trials=num_trials, timeout=timeout_choice)\n",
        "  print(\"Best parameters:\", study.best_params)\n",
        "\n",
        "  best_model = LinearSVR(C=study.best_params['C'], epsilon=study.best_params['epsilon'],\n",
        "                        random_state=28, max_iter=10000)\n",
        "  best_model.fit(X_train, y_train)\n",
        "  #joblib.dump(best_model, 'PPG_SVR.pkl')\n",
        "  return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8uNS5w0gAHH"
      },
      "outputs": [],
      "source": [
        "def RF_tune(X_train, y_train, cv_choice, num_trials, timeout_choice):\n",
        "  def RF_objective(trial, cv_runs, X_train, y_train):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 100)#300)\n",
        "    max_depth = trial.suggest_int('max_depth', 5, 50)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 10, 20)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
        "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
        "\n",
        "    model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,\n",
        "        max_features=max_features, random_state=28, n_jobs=-1)\n",
        "\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=cv_runs, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "    mean_score = np.mean(scores)\n",
        "    return -mean_score\n",
        "\n",
        "  study = optuna.create_study(direction='minimize')\n",
        "  study.optimize(lambda trial: RF_objective(trial, cv_choice, X_train, y_train), n_trials=num_trials, timeout=timeout_choice)\n",
        "  print(\"Best parameters:\", study.best_params)\n",
        "\n",
        "  best_model = RandomForestRegressor(\n",
        "      n_estimators=study.best_params['n_estimators'], max_depth=study.best_params['max_depth'],\n",
        "      min_samples_split=study.best_params['min_samples_split'], min_samples_leaf=study.best_params['min_samples_leaf'],\n",
        "      max_features=study.best_params['max_features'], random_state=28, n_jobs=-1)\n",
        "  best_model.fit(X_train, y_train)\n",
        "  #joblib.dump(best_model, 'PPG_RF.pkl')\n",
        "  return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYrV1hGVhgzH"
      },
      "outputs": [],
      "source": [
        "def BR_tune(X_train, y_train, cv_choice, num_trials, timeout_choice):\n",
        "  def BR_objective(trial, cv_runs, X_train, y_train):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 10, 100)\n",
        "    max_samples = trial.suggest_float('max_samples', 0.5, 1.0)\n",
        "    max_features = trial.suggest_float('max_features', 0.5, 1.0)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 30)  # For DecisionTreeRegressor\n",
        "\n",
        "    base_estimator = DecisionTreeRegressor(max_depth=max_depth, random_state=28)\n",
        "    model = BaggingRegressor(estimator=base_estimator, n_estimators=n_estimators,\n",
        "        max_samples=max_samples, max_features=max_features, random_state=28, n_jobs=-1)\n",
        "\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=cv_runs, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "    mean_score = np.mean(scores)\n",
        "    return -mean_score\n",
        "\n",
        "  study = optuna.create_study(direction='minimize')\n",
        "  study.optimize(lambda trial: BR_objective(trial, cv_choice, X_train, y_train), n_trials=num_trials, timeout=timeout_choice)\n",
        "  print(\"Best parameters:\", study.best_params)\n",
        "\n",
        "  best_base_estimator = DecisionTreeRegressor(max_depth=study.best_params['max_depth'], random_state=28)\n",
        "  best_model = BaggingRegressor(estimator=best_base_estimator, n_estimators=study.best_params['n_estimators'],\n",
        "      max_samples=study.best_params['max_samples'], max_features=study.best_params['max_features'],\n",
        "      random_state=28, n_jobs=-1)\n",
        "  best_model.fit(X_train, y_train)\n",
        "  #joblib.dump(best_model, 'PPG_BR.pkl')\n",
        "  return best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4dHDJtOsKU_"
      },
      "source": [
        "# **ML Algorithms**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLVl7ooxvt7q"
      },
      "outputs": [],
      "source": [
        "def RLE_Model(xTrain, xTest, yTrain, yTest, choice, predict_df, tar_sca): #Function to run Ridge, Lasso, or ElasticNet model\n",
        "  if(choice==\"Ridge\"):\n",
        "    pipeline = Ridge_tune(xTrain, yTrain, 10, 200, 15)\n",
        "\n",
        "  if(choice==\"Lasso\"):\n",
        "    pipeline = Lasso_tune(xTrain, yTrain, 10, 200, 15)\n",
        "\n",
        "  if(choice==\"Elastic\"):\n",
        "    pipeline = Elastic_tune(xTrain, yTrain, 10, 200, 15)\n",
        "\n",
        "  modelResults = Predict_Scores(pipeline, xTrain, xTest, yTrain, yTest, tar_sca)\n",
        "  #print(f'Chosen alpha  {pipeline.steps[0][1].alpha_:.6f}')\n",
        "  #print(f'Intercept (b) {pipeline.steps[0][1].intercept_:.6f}')\n",
        "  #print(pd.Series(pipeline.steps[0][1].coef_, index=X.columns),'\\n')\n",
        "  return modelResults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FpU87Mgvvx0s"
      },
      "outputs": [],
      "source": [
        "def GBR_model(xTrain, xTest, yTrain, yTest, predict_df, tar_sca):\n",
        "  model = GBR_tune(xTrain, yTrain, 3, 200, 15)\n",
        "  modelResults = Predict_Scores(model, xTrain, xTest, yTrain, yTest, tar_sca)\n",
        "  return modelResults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ms2SSQ_3ncH"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "def SVM_models(xTrain, xTest, yTrain, yTest, choice, predict_df, tar_sca):\n",
        "  if(choice==\"rbf\"):\n",
        "    model = SVR_rbf_tune(xTrain, yTrain, 10, 200, 15)\n",
        "    modelResults = Predict_Scores(model, xTrain, xTest, yTrain, yTest, tar_sca)\n",
        "\n",
        "  if(choice==\"poly\"):\n",
        "    model = SVR_poly_tune(xTrain, yTrain, 10, 200, 15)\n",
        "    modelResults = Predict_Scores(model, xTrain, xTest, yTrain, yTest, tar_sca)\n",
        "\n",
        "  modelResults = Predict_Scores(model, xTrain, xTest, yTrain, yTest, tar_sca)\n",
        "  return modelResults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luksQpOa9mx6"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "def SVR_model(xTrain, xTest, yTrain, yTest, predict_df, tar_sca):\n",
        "  model = SVR_tune(xTrain, yTrain, 10, 200, 15)\n",
        "  modelResults = Predict_Scores(model, xTrain, xTest, yTrain, yTest, tar_sca)\n",
        "  return modelResults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfB2M7eKfne7"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "def RF_model(xTrain, xTest, yTrain, yTest, predict_df, tar_sca):\n",
        "  model = RF_tune(xTrain, yTrain, 3, 200, 15)\n",
        "  modelResults = Predict_Scores(model, xTrain, xTest, yTrain, yTest, tar_sca)\n",
        "  return modelResults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppib1skHfgGk"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "def BR_model(xTrain, xTest, yTrain, yTest, predict_df, tar_sca):\n",
        "  model = BR_tune(xTrain, yTrain, 3, 200, 15)\n",
        "  modelResults = Predict_Scores(model, xTrain, xTest, yTrain, yTest, tar_sca)\n",
        "  return modelResults"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4QbyjhZi-0Z"
      },
      "source": [
        "# **Inputs/LOOCV Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6Wz_o_8rgX0"
      },
      "outputs": [],
      "source": [
        "def get_inputs(data_frame, y, tr_index, te_index, scaler_choice, thresh, if_final):\n",
        "#Feature Importance:\n",
        "  if scaler_choice == \"MinMax\":\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler2 = MinMaxScaler()\n",
        "  else:\n",
        "    scaler = StandardScaler()\n",
        "    scaler2 = StandardScaler()\n",
        "\n",
        "  if if_final == 'yes':\n",
        "    data_scaled_train, data_scaled_test, y_train, y_test = data_frame, pd.DataFrame(), y, pd.DataFrame()\n",
        "  else:\n",
        "    data_scaled_train, data_scaled_test, y_train, y_test = data_frame.iloc[tr_index], data_frame.iloc[[te_index]], y.iloc[tr_index], y.iloc[te_index]\n",
        "\n",
        "  train_scaled = pd.DataFrame(scaler.fit_transform(data_scaled_train), columns = data_frame.columns)\n",
        "  y_train = pd.Series(scaler2.fit_transform(y_train.values.reshape(-1, 1)).flatten())\n",
        "  train_scaled_correlated, correlations_df = correlation(train_scaled, thresh, y_train) #\n",
        "  train_scaled_correlated = pd.DataFrame(train_scaled_correlated)\n",
        "\n",
        "  if if_final == 'no':\n",
        "    y_test = pd.Series(y_test)\n",
        "    y_test = y_test.values.reshape(-1, 1)\n",
        "    y_test = scaler2.transform(y_test).flatten()\n",
        "    test_scaled = pd.DataFrame(scaler.transform(data_scaled_test), columns=data_frame.columns)\n",
        "    test_scaled_correlated = test_scaled.loc[:, train_scaled_correlated.columns] #Test data with only correlated inputs\n",
        "  else:\n",
        "    test_scaled_correlated = data_scaled_test\n",
        "\n",
        "  print(len(train_scaled_correlated.columns))\n",
        "\n",
        "  return train_scaled_correlated, test_scaled_correlated, scaler, scaler2, y_train, y_test, correlations_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3gOTUsp3kQJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_swiss_roll\n",
        "from sklearn.manifold import LocallyLinearEmbedding\n",
        "from sklearn.decomposition import PCA\n",
        "def reduce_df(x_tr, x_te, reduction_choice, if_final):\n",
        "  pca=PCA(n_components = 3, random_state=28) #n_components = None, 420\n",
        "  lle = LocallyLinearEmbedding(n_components=3, n_neighbors=5, random_state=28) #n_components=2 is default, 850\n",
        "\n",
        "  if reduction_choice == \"PCA\":\n",
        "    X_tr_PCA = pca.fit_transform(x_tr)\n",
        "    if if_final == \"no\":\n",
        "      X_te_PCA = pca.transform(x_te)\n",
        "    else:\n",
        "      X_te_PCA = x_te\n",
        "    #print(\"Principal axes:\\n\", pca.components_.tolist())\n",
        "    #print(\"Explained variance:\\n\", pca.explained_variance_.tolist())\n",
        "    print(\"Mean:\", pca.mean_)\n",
        "    return X_tr_PCA, X_te_PCA, pca\n",
        "  else:\n",
        "    X_unrolled_train = lle.fit_transform(x_tr)\n",
        "    if if_final == \"no\":\n",
        "      X_unrolled_test = lle.transform(x_te)\n",
        "    else:\n",
        "      X_unrolled_test = x_te\n",
        "    return X_unrolled_train, X_unrolled_test, lle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sZZxhEdi9Z4w"
      },
      "outputs": [],
      "source": [
        "from joblib import Parallel, delayed\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# Define the function that processes each fold of LOO-CV and can make final model\n",
        "def process_fold(train_index, test_index, X, y):\n",
        "    X_train, X_test, scalerPPG, scalerY, Y_train, Y_test, correlations_df = get_inputs(X, y, train_index, test_index[0], \"\", 0.1, 'no')\n",
        "\n",
        "    #Select only top 40 most correlated columns:\n",
        "    common_columns = list(set(X_train.columns).intersection(correlations_df.columns))\n",
        "    if not common_columns:\n",
        "        # Handle the case where there are no correlated columns\n",
        "        return None\n",
        "    X_train_with_corrs = pd.concat([X_train[common_columns], correlations_df[common_columns]])\n",
        "    X_train_with_corrs = X_train_with_corrs.transpose()\n",
        "    X_train_with_corrs = X_train_with_corrs.sort_values(by='corrs', ascending = False, key=abs)\n",
        "    X_train_with_corrs = X_train_with_corrs.head(50)\n",
        "    X_train_reduced = X_train_with_corrs.drop('corrs', axis = 1) #drop corrs column\n",
        "    X_train_reduced = X_train_reduced.transpose()\n",
        "    X_train_reduced.reset_index(drop = True, inplace = True)\n",
        "    X_test_reduced = pd.DataFrame(X_test, columns=X_train_reduced.columns)\n",
        "\n",
        "    #Reduce with PCA or LLE:\n",
        "    print(len(X_train_reduced.columns))\n",
        "    X_train_reduced_PCA, X_test_reduced_PCA, pca_reducer = reduce_df(X_train_reduced, X_test_reduced, \"PCA\", 'no')\n",
        "    #X_train_reduced_LLE, X_test_reduced_LLE, lle_reducer = reduce_df(X_train_reduced, X_test_reduced, \"LLE\", 'no')\n",
        "\n",
        "    #Create the model:\n",
        "    #model = RLE_Model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, \"Ridge\", X_test_reduced_LLE, scalerY)\n",
        "    #model = RLE_Model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, \"Lasso\", X_test_reduced_LLE, scalerY)\n",
        "    #model = RF_model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, X_test_reduced_LLE, scalerY)\n",
        "    #model = SVR_model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, X_test_reduced_LLE, scalerY)\n",
        "    #model = GBR_model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, X_test_reduced_LLE, scalerY)\n",
        "    #model = RLE_Model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, \"Elastic\", X_test_reduced_LLE, scalerY)\n",
        "\n",
        "    #model = SVM_models(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, \"rbf\", X_test_reduced_LLE, scalerY)\n",
        "    #model = SVM_models(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, \"poly\", X_test_reduced_LLE, scalerY)\n",
        "    #model = BR_model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, X_test_reduced_LLE, scalerY)\n",
        "\n",
        "    #model = RLE_Model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, \"Ridge\", X_test_reduced_PCA, scalerY)\n",
        "    #model = RLE_Model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, \"Lasso\", X_test_reduced_PCA, scalerY)\n",
        "    #model = RF_model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, X_test_reduced_PCA, scalerY)\n",
        "    #model = SVR_model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, X_test_reduced_PCA, scalerY)\n",
        "    #model = GBR_model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, X_test_reduced_PCA, scalerY)\n",
        "    model = RLE_Model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, \"Elastic\", X_test_reduced_PCA, scalerY)\n",
        "\n",
        "    #model = SVM_models(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, \"rbf\", X_test_reduced_PCA, scalerY)\n",
        "    #model = SVM_models(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, \"poly\", X_test_reduced_PCA, scalerY)\n",
        "    #model = BR_model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, X_test_reduced_PCA, scalerY)\n",
        "\n",
        "    return model #Return the model for each fold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWimHdH6khJZ"
      },
      "source": [
        "# **Test 1 Fold**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAYkKsONkguW"
      },
      "outputs": [],
      "source": [
        "X = inputs\n",
        "y = playoff_stats['oPPG_Playoffs']\n",
        "len_df = len(X)\n",
        "train_index = list(range(len_df-1))\n",
        "test_index = list(range((len_df-1), len_df))\n",
        "X_train, X_test, scalerPPG, scalerY, Y_train, Y_test, correlations_df = get_inputs(X, y, nums, test_index[0], \"\", 0.1, 'no')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.columns"
      ],
      "metadata": {
        "collapsed": true,
        "id": "H2dA4I2DQSf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UVCv7Zh7kisF"
      },
      "outputs": [],
      "source": [
        "common_columns = list(set(X_train.columns).intersection(correlations_df.columns))\n",
        "X_train_with_corrs = pd.concat([X_train[common_columns], correlations_df[common_columns]])\n",
        "X_train_with_corrs = X_train_with_corrs.transpose()\n",
        "X_train_with_corrs = X_train_with_corrs.sort_values(by='corrs', ascending = False, key=abs)\n",
        "X_train_with_corrs = X_train_with_corrs.head(50)\n",
        "X_train_reduced = X_train_with_corrs.drop('corrs', axis = 1) #drop corrs column\n",
        "X_train_reduced = X_train_reduced.transpose()\n",
        "X_train_reduced.reset_index(drop = True, inplace = True)\n",
        "X_test_reduced = pd.DataFrame(X_test, columns=X_train_reduced.columns)\n",
        "\n",
        "#Reduce with PCA or LLE:\n",
        "X_train_reduced_PCA, X_test_reduced_PCA, pca_reducer = reduce_df(X_train_reduced, X_test_reduced, \"PCA\", 'no')\n",
        "#X_train_reduced_LLE, X_test_reduced_LLE, lle_reducer = reduce_df(X_train_reduced, X_test_reduced, \"LLE\", 'no')\n",
        "\n",
        "#Create the model:\n",
        "#model = RLE_Model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, \"Ridge\", X_test_reduced_LLE, scalerY)\n",
        "#model = RLE_Model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, \"Lasso\", X_test_reduced_LLE, scalerY)\n",
        "#model = RLE_Model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, \"Elastic\", X_test_reduced_LLE, scalerY) #.2, 1.3\n",
        "#model = GBR_model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, X_test_reduced_LLE, scalerY)\n",
        "#model = SVM_models(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, \"rbf\", X_test_reduced_LLE, scalerY)\n",
        "#model = SVM_models(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, \"poly\", X_test_reduced_LLE, scalerY)\n",
        "#model = SVR_model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, X_test_reduced_LLE, scalerY)\n",
        "#model = RF_model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, X_test_reduced_LLE, scalerY)\n",
        "#model = BR_model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, X_test_reduced_LLE, scalerY)\n",
        "\n",
        "#model = RLE_Model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, \"Ridge\", X_test_reduced_PCA, scalerY) #.2, 1.2\n",
        "#model = RLE_Model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, \"Lasso\", X_test_reduced_PCA, scalerY) #.2, 1.2\n",
        "model = RLE_Model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, \"Elastic\", X_test_reduced_PCA, scalerY) #.2, 1.2\n",
        "#model = GBR_model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, X_test_reduced_PCA, scalerY) #0, 1.5\n",
        "#model = SVM_models(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, \"rbf\", X_test_reduced_PCA, scalerY) #.1, 1.3\n",
        "#model = SVM_models(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, \"poly\", X_test_reduced_PCA, scalerY) #.1, 1.2\n",
        "#model = SVR_model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, X_test_reduced_PCA, scalerY) #.2, 1.2\n",
        "#model = RF_model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, X_test_reduced_PCA, scalerY) #.1, 1.2\n",
        "#model = BR_model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, X_test_reduced_PCA, scalerY) #.1, 1.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gimKSs5rrWWW"
      },
      "source": [
        "# **Run LOO-CV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baeBkT2AohI6",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Initialize LOO and Joblib Parallel\n",
        "X = inputs\n",
        "y = playoff_stats['oPPG_Playoffs'] #PPG_Playoffs, Points/Att_Playoffs\n",
        "loo = LeaveOneOut()\n",
        "results = Parallel(n_jobs=-1)(delayed(process_fold)(train_idx, test_idx, X, y)\n",
        "                              for train_idx, test_idx in loo.split(X))\n",
        "train_N_scores = 0\n",
        "test_MAPE_scores = 0\n",
        "train_avg_scores = 0\n",
        "test_avg_scores = 0\n",
        "len_df = len(X)\n",
        "\n",
        "for i in range(len_df):\n",
        "  train_N_scores = results[i][0] + train_N_scores\n",
        "for i in range(len_df):\n",
        "  train_avg_scores = results[i][2] + train_avg_scores\n",
        "for i in range(len_df):\n",
        "  test_avg_scores = results[i][3] + test_avg_scores\n",
        "for i in range(len_df):\n",
        "  test_MAPE_scores = results[i][4] + test_MAPE_scores\n",
        "\n",
        "print(f'AVG Normalized train acuraacy: {((train_N_scores/len_df)):.3f}')\n",
        "print(f'AVG inv transformed train accuracy: {((train_avg_scores.flatten()[0]/len_df)):.3f}')\n",
        "print(f'AVG inv transformed test accuracy: {((test_avg_scores[0]/len_df)):.3f}')\n",
        "print(f'AVG MAPE test accuracy: {((test_MAPE_scores/len_df)):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSUQdmSRnKO8"
      },
      "source": [
        "# **Final Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zU4HlHW3tgWS"
      },
      "outputs": [],
      "source": [
        "X = inputs#.iloc[:, 0:616]\n",
        "y = playoff_stats['oPPG_Playoffs'] #Points/Att_Playoffs, PPG_Playoffs\n",
        "len_df = len(X)\n",
        "train_index = list(range(len_df))\n",
        "test_index = list(range(1))\n",
        "\n",
        "#X_train, X_test, scalerPPG, scalerY, Y_train, Y_test, correlations_df = get_inputs(X, y, train_index, test_index[0], \"\", 0.1, 'yes')\n",
        "common_columns = list(set(X_train.columns).intersection(correlations_df.columns))\n",
        "X_train_with_corrs = pd.concat([X_train[common_columns], correlations_df[common_columns]])\n",
        "X_train_with_corrs = X_train_with_corrs.transpose()\n",
        "X_train_with_corrs = X_train_with_corrs.sort_values(by='corrs', ascending = False, key=abs)\n",
        "X_train_with_corrs = X_train_with_corrs.head(50)\n",
        "X_train_reduced = X_train_with_corrs.drop('corrs', axis = 1) #drop corrs column\n",
        "X_train_reduced = X_train_reduced.transpose()\n",
        "X_train_reduced.reset_index(drop = True, inplace = True)\n",
        "\n",
        "X_test_reduced = X_test\n",
        "X_train_reduced_PCA, X_test_reduced_PCA, pca_reducer = reduce_df(X_train_reduced, X_test_reduced, \"PCA\", 'yes')\n",
        "#X_train_reduced_LLE, X_test_reduced_LLE, lle_reducer = reduce_df(X_train_reduced, X_test_reduced, \"LLE\", 'yes')\n",
        "\n",
        "#model = RLE_Model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, \"Ridge\", X_test_reduced_LLE, scalerY)\n",
        "#model = RLE_Model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, \"Lasso\", X_test_reduced_LLE, scalerY)\n",
        "#model = RLE_Model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, \"Elastic\", X_test_reduced_LLE, scalerY)\n",
        "#model = GBR_model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, X_test_reduced_LLE, scalerY)\n",
        "#model = SVM_models(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, \"rbf\", X_test_reduced_LLE, scalerY)\n",
        "#model = SVM_models(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, \"poly\", X_test_reduced_LLE, scalerY)\n",
        "#model = SVR_model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, X_test_reduced_LLE, scalerY)\n",
        "#model = RF_model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, X_test_reduced_LLE, scalerY)\n",
        "#model = BR_model(X_train_reduced_LLE, X_test_reduced_LLE, Y_train, Y_test, X_test_reduced_LLE, scalerY)\n",
        "\n",
        "#model = RLE_Model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, \"Ridge\", X_test_reduced_PCA, scalerY)\n",
        "#model = RLE_Model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, \"Lasso\", X_test_reduced_PCA, scalerY)\n",
        "model = RLE_Model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, \"Elastic\", X_test_reduced_PCA, scalerY)\n",
        "#model = GBR_model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, X_test_reduced_PCA, scalerY)\n",
        "#model = SVM_models(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, \"rbf\", X_test_reduced_PCA, scalerY)\n",
        "#model = SVM_models(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, \"poly\", X_test_reduced_PCA, scalerY)\n",
        "#model = SVR_model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, X_test_reduced_PCA, scalerY)\n",
        "#model = RF_model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, X_test_reduced_PCA, scalerY)\n",
        "#model = BR_model(X_train_reduced_PCA, X_test_reduced_PCA, Y_train, Y_test, X_test_reduced_PCA, scalerY)\n",
        "\n",
        "print(f'AVG Normalized Score: {((model[0])):.3f}')\n",
        "print(f'AVG Error: {((model[2])):.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHnkX4evIu9h"
      },
      "source": [
        "# **oPPG**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ridge Folds:** PCA - 50, 2, 10\n",
        "*   AVG Normalized train accuracy: 0.142\n",
        "*   AVG inv transformed train accuracy: 2.049\n",
        "*   AVG inv transformed test accuracy: 5.785\n",
        "*   AVG MAPE test accuracy: 0.2373\n",
        "\n",
        "**Ridge Final**:\n",
        "*   AVG Normalized Score: 0.141\n",
        "*   AVG Error: 2.055\n",
        "*   Normalized RMSE:0.2\n",
        "*   Normalized MAE:0.13"
      ],
      "metadata": {
        "id": "VFAaCElFSfeg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOu0AePiaam-"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "oPPG_model = joblib.load('oPPG_Ridge.pkl')\n",
        "oPPG_inputs = pd.read_csv('oPPG Inputs.csv')\n",
        "inputs = pd.read_csv('NFL oPPG inputs.csv')\n",
        "playoff_stats = pd.read_csv('playoff_stats_NFL.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWNQj9mPbVsv"
      },
      "outputs": [],
      "source": [
        "X = inputs\n",
        "y = playoff_stats['oPPG_Playoffs'] #Points/Att_Playoffs, PPG_Playoffs\n",
        "len_df = len(X)\n",
        "train_index = list(range(len_df))\n",
        "test_index = list(range(1))\n",
        "\n",
        "X_train, X_test, scaler_oPPG, scalerY, Y_train, Y_test, correlations_df = get_inputs(X, y, train_index, test_index[0], \"\", 0.1, 'yes')\n",
        "common_columns = list(set(X_train.columns).intersection(correlations_df.columns))\n",
        "X_train_with_corrs = pd.concat([X_train[common_columns], correlations_df[common_columns]])\n",
        "X_train_with_corrs = X_train_with_corrs.transpose()\n",
        "X_train_with_corrs = X_train_with_corrs.sort_values(by='corrs', ascending = False, key=abs)\n",
        "X_train_with_corrs = X_train_with_corrs.head(50)\n",
        "X_train_reduced = X_train_with_corrs.drop('corrs', axis = 1) #drop corrs column\n",
        "X_train_reduced = X_train_reduced.transpose()\n",
        "X_train_reduced.reset_index(drop = True, inplace = True)\n",
        "\n",
        "X_test_reduced = X_test\n",
        "#X_train_reduced_LLE, X_test_reduced_LLE, oPPG_lle_reducer = reduce_df(X_train_reduced, X_test_reduced, \"LLE\", 'yes')\n",
        "X_train_reduced_PCA, X_test_reduced_PCA, oPPG_pca_reducer = reduce_df(X_train_reduced, X_test_reduced, \"PCA\", 'yes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzAEGH2xdaUa"
      },
      "outputs": [],
      "source": [
        "oPPG_scaler = StandardScaler()\n",
        "trained_features_to_scale = X[X_train_reduced.columns]\n",
        "trained_features_scaled = oPPG_scaler.fit_transform(trained_features_to_scale)\n",
        "\n",
        "oPPG_inputs_scaled = oPPG_scaler.transform(oPPG_inputs)\n",
        "oPPG_inputs_scaled_trans = oPPG_pca_reducer.transform(oPPG_inputs_scaled)\n",
        "predictions = oPPG_model.predict(oPPG_inputs_scaled_trans)\n",
        "predictions = pd.Series(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEgEYO_sTh3t"
      },
      "source": [
        "# **PPG**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlyPEa1BW0tD"
      },
      "source": [
        "**Linear SVR Folds:**\n",
        "* AVG Normalized train accuracy: 0.171\n",
        "* AVG inv transformed train accuracy: 2.917\n",
        "* AVG inv transformed test accuracy: 4.572\n",
        "\n",
        "**Linear SVR Final:**\n",
        "* Avg. Normalized Score:0.2\n",
        "* Normalized RMSE:0.3\n",
        "* Normalized MAE:0.21\n",
        "* Avg. Error: 0.8226\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGDRj9vy3ClF"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "PPG_model = joblib.load('PPG_SVR.pkl')\n",
        "PPG_inputs = pd.read_csv('PPG_Inputs.csv')\n",
        "inputs = pd.read_csv('NFL PPG inputs_Use.csv')\n",
        "playoff_stats = pd.read_csv('playoff_stats_NFL.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf4eAfGp5Vh2"
      },
      "outputs": [],
      "source": [
        "X = inputs\n",
        "y = playoff_stats['PPG_Playoffs'] #Points/Att_Playoffs, PPG_Playoffs\n",
        "len_df = len(X)\n",
        "train_index = list(range(len_df))\n",
        "test_index = list(range(1))\n",
        "\n",
        "X_train, X_test, scaler_PPG, scalerY, Y_train, Y_test, correlations_df = get_inputs(X, y, train_index, test_index[0], \"\", 0.1, 'yes')\n",
        "common_columns = list(set(X_train.columns).intersection(correlations_df.columns))\n",
        "X_train_with_corrs = pd.concat([X_train[common_columns], correlations_df[common_columns]])\n",
        "X_train_with_corrs = X_train_with_corrs.transpose()\n",
        "X_train_with_corrs = X_train_with_corrs.sort_values(by='corrs', ascending = False, key=abs)\n",
        "X_train_with_corrs = X_train_with_corrs.head(50)\n",
        "X_train_reduced = X_train_with_corrs.drop('corrs', axis = 1) #drop corrs column\n",
        "X_train_reduced = X_train_reduced.transpose()\n",
        "X_train_reduced.reset_index(drop = True, inplace = True)\n",
        "\n",
        "X_test_reduced = X_test\n",
        "#X_train_reduced_LLE, X_test_reduced_LLE, PPG_lle_reducer = reduce_df(X_train_reduced, X_test_reduced, \"LLE\", 'yes')\n",
        "X_train_reduced_PCA, X_test_reduced_PCA, PPG_pca_reducer = reduce_df(X_train_reduced, X_test_reduced, \"PCA\", 'yes')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = PPG_model.predict(X_train_reduced_PCA)\n",
        "MSE = mean_squared_error(Y_train, y_pred)\n",
        "MAE = mean_absolute_error(Y_train, y_pred)\n",
        "\n",
        "range_y = Y_train.max() - Y_train.min()\n",
        "Normalized_RMSE = (np.sqrt(MSE)/abs(range_y))\n",
        "Normalized_MAE = (MAE/abs(range_y))\n",
        "Avg_Normalized_Score = (Normalized_RMSE + Normalized_MAE)/2\n",
        "Avg_Normalized_Score = Avg_Normalized_Score.item() if isinstance(Avg_Normalized_Score, np.ndarray) else Avg_Normalized_Score\n",
        "print(f'Avg. Normalized Score:{ Avg_Normalized_Score:.1f}')\n",
        "print(f'Normalized RMSE:{ Normalized_RMSE:.1f}')\n",
        "print(f'Normalized MAE:{ Normalized_MAE:.2f}')\n",
        "\n",
        "#Calculate avg error, handling single-element arrays and ensuring it is a scalar\n",
        "avg_error = np.mean(np.abs(y_pred-Y_train))\n",
        "\n",
        "print(f'MAE:{ MAE:.3f}')\n",
        "print(f'RMSE:{ np.sqrt(MSE):.3f}')\n",
        "print(f'Avg. Error:{avg_error:.4f}')"
      ],
      "metadata": {
        "id": "V6qC28i3quIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qOTlGNw5XPj"
      },
      "outputs": [],
      "source": [
        "PPG_scaler = StandardScaler()\n",
        "trained_features_to_scale = X[X_train_reduced.columns]\n",
        "trained_features_scaled = PPG_scaler.fit_transform(trained_features_to_scale)\n",
        "\n",
        "PPG_inputs_scaled = PPG_scaler.transform(PPG_inputs)\n",
        "PPG_inputs_scaled_trans = PPG_pca_reducer.transform(PPG_inputs_scaled)\n",
        "predictions = PPG_model.predict(PPG_inputs_scaled_trans)\n",
        "predictions_inv_trans = scalerY.inverse_transform(predictions.reshape(-1, 1))\n",
        "predictions_inv_trans = pd.Series(predictions_inv_trans.flatten())\n",
        "round(predictions_inv_trans, 1)\n",
        "predictions_inv_trans.to_csv('PPG_predictions.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "mount_file_id": "1Vm8WmlMWl5qPkDh4nqbzn64vOM6ndqxq",
      "authorship_tag": "ABX9TyNAW1RpTsZgYXXhNQ0eXKxF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}